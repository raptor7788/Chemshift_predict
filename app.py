import torch
import streamlit as st
import numpy as np
from torch_geometric.utils import from_smiles
from torch_geometric.nn import AttentiveFP, GCNConv
from torch_geometric.nn import global_mean_pool, global_max_pool, global_add_pool


# Load the models
def load_attentivefp_model():
    # å®šä¹‰AttentiveFPæ¨¡å‹ï¼ˆéœ€ä¸è®­ç»ƒæ—¶å‚æ•°ä¸€è‡´ï¼‰
    model = AttentiveFP(
        in_channels=9,  # èŠ‚ç‚¹ç‰¹å¾ç»´åº¦
        hidden_channels=66,  # éšè—å±‚ç»´åº¦
        out_channels=1,  # è¾“å‡ºç»´åº¦
        edge_dim=3,  # è¾¹ç‰¹å¾ç»´åº¦
        num_layers=5,  # å±‚æ•°
        num_timesteps=3,  # æ—¶é—´æ­¥æ•°
        dropout=0.0446259777448801  # dropoutç‡
    )
    # åŠ è½½state_dict
    model.load_state_dict(
        torch.load("Resources/AttentiveFP_model.pt", map_location=torch.device("cpu"), weights_only=True))
    model.eval()
    return model


import torch
from torch_geometric.nn import GCN, global_mean_pool, global_max_pool, global_add_pool


class NMRShiftModel(torch.nn.Module):
    def __init__(
            self,
            in_channels=9,
            hidden_channels=185,  # Match your load_gcn_model
            num_layers=4,  # Match checkpoint (convs.0 to convs.3)
            out_channels=1,
            dropout=0.11080081715730111,  # Match your load_gcn_model
            pooling_method='max',  # Match your load_gcn_model
            act='relu',
            jk='cat'  # Changed to 'cat' to match gcn.lin.weight shape [185, 740]
    ):
        super().__init__()
        # Use PyG's GCN model
        self.gcn = GCN(
            in_channels=in_channels,
            hidden_channels=hidden_channels,
            num_layers=num_layers,
            out_channels=hidden_channels,  # Output to hidden_channels first
            dropout=dropout,
            norm='batch_norm',
            jk=jk,
            act=act
        )
        # Final linear layer to get to out_channels
        self.lin = torch.nn.Linear(hidden_channels, out_channels)
        self.pooling_method = pooling_method

    def forward(self, x, edge_index, batch):
        # Apply GCN
        x = self.gcn(x, edge_index)

        # Apply global pooling based on the selected method
        if self.pooling_method == 'mean':
            x = global_mean_pool(x, batch)
        elif self.pooling_method == 'add':
            x = global_add_pool(x, batch)
        elif self.pooling_method == 'max':
            x = global_max_pool(x, batch)

        # Apply final linear layer
        x = self.lin(x)
        return x


def load_gcn_model():
    # Define GCN model with parameters matching the checkpoint
    model = NMRShiftModel(
        in_channels=9,
        hidden_channels=185,
        num_layers=4,
        out_channels=1,
        dropout=0.11080081715730111,
        pooling_method='max',
        act='relu',
        jk='cat'  # Changed to 'cat'
    )
    # Load state_dict
    model.load_state_dict(
        torch.load("Resources/GCN_model.pt", map_location=torch.device("cpu"), weights_only=True))
    model.eval()
    return model

# Function to inverse transform the scaled predictions to original scale
def inverse_transform(scaled_value):
    # ä½¿ç”¨æä¾›çš„ä¸­å¿ƒå€¼å’Œç¼©æ”¾å› å­è¿›è¡Œé€†å˜æ¢
    center = 23.47
    scale = 22.69999886
    return scaled_value * scale + centerss


# Function to predict chemical shift
def predict_chemical_shift(smiles_list, model_type='attentivefp'):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # Load the selected model
    if model_type == 'attentivefp':
        model = load_attentivefp_model().to(device)
    else:  # gcn
        model = load_gcn_model().to(device)

    predictions = []
    raw_predictions = []
    for smile in smiles_list:
        try:
            # Convert SMILES to graph
            g = from_smiles(smile)
            g.x = g.x.float()
            g = g.to(device)

            # Add batch information
            g.batch = torch.zeros(g.num_nodes, dtype=torch.long, device=device)

            # Perform prediction based on model type
            with torch.no_grad():
                if model_type == 'attentivefp':
                    pred = model(g.x, g.edge_index, g.edge_attr, g.batch)
                else:  # gcn
                    pred = model(g.x, g.edge_index, g.batch)

            # Get raw prediction value
            raw_pred = pred.item()
            raw_predictions.append(raw_pred)

            # Apply inverse transform to get the actual chemical shift value
            actual_pred = inverse_transform(raw_pred)
            predictions.append(actual_pred)
        except Exception as e:
            predictions.append(f"Error: {str(e)}")
            raw_predictions.append(None)

    return predictions, raw_predictions


# Page configuration
st.set_page_config(
    page_title="Chemical Shift Prediction",
    page_icon="ğŸ§ª",
    layout="wide"
)

# Sidebar for navigation
st.sidebar.title("å¯¼èˆªèœå•")
page = st.sidebar.radio("é€‰æ‹©é¡µé¢", ["é¦–é¡µ", "å…³äº"])

if page == "é¦–é¡µ":
    # Streamlit UI for prediction
    st.title('åŒ–å­¦ä½ç§»é¢„æµ‹ (Chemical Shift Prediction)')
    st.write('è¯·åœ¨ä¸‹æ–¹è¾“å…¥SMILESå­—ç¬¦ä¸²ï¼Œç‚¹å‡»"é¢„æµ‹"æŒ‰é’®è·å–åŒ–å­¦ä½ç§»å€¼ã€‚')

    # Example SMILES
    example_smiles = "CC(=O)Oc1ccccc1C(=O)O"
    st.write(f"ç¤ºä¾‹SMILES: `{example_smiles}`")

    smiles_input = st.text_area("SMILESå­—ç¬¦ä¸² (æ¯è¡Œä¸€ä¸ª)", height=150)

    # Model selection
    model_type = st.radio(
        "é€‰æ‹©é¢„æµ‹æ¨¡å‹",
        ["AttentiveFP", "GCN"],
        horizontal=True,
        help="AttentiveFP: ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶çš„å›¾ç¥ç»ç½‘ç»œ; GCN: å›¾å·ç§¯ç¥ç»ç½‘ç»œ"
    )

    # Convert model selection to lowercase for internal use
    model_type_lower = model_type.lower()

    # Option to show normalized values
    show_normalized = st.checkbox("åŒæ—¶æ˜¾ç¤ºå½’ä¸€åŒ–å€¼", value=False)

    col1, col2 = st.columns([1, 3])
    with col1:
        predict_button = st.button("é¢„æµ‹", type="primary")

    if predict_button:
        if smiles_input:
            with st.spinner('æ­£åœ¨è¿›è¡Œé¢„æµ‹...'):
                smiles_list = [s.strip() for s in smiles_input.split('\n') if s.strip()]
                shift_predictions, raw_predictions = predict_chemical_shift(smiles_list, model_type_lower)

                st.write(f"### é¢„æµ‹ç»“æœ (ä½¿ç”¨ {model_type} æ¨¡å‹)")

                # Display results without using st.table
                for i, (smile, pred, raw_pred) in enumerate(zip(smiles_list, shift_predictions, raw_predictions)):
                    result_container = st.container()
                    with result_container:
                        if show_normalized and not isinstance(pred, str):
                            cols = st.columns([1, 3, 2, 2])
                            with cols[0]:
                                st.write(f"**#{i + 1}**")
                            with cols[1]:
                                st.write(f"**SMILES:** `{smile}`")
                            with cols[2]:
                                if isinstance(pred, float):
                                    st.write(f"**é¢„æµ‹çš„åŒ–å­¦ä½ç§»:** {pred:.4f} ppm")
                                else:
                                    st.write(f"**é”™è¯¯:** {pred}")
                            with cols[3]:
                                if raw_pred is not None:
                                    st.write(f"**å½’ä¸€åŒ–å€¼:** {raw_pred:.4f}")
                        else:
                            cols = st.columns([1, 4, 2])
                            with cols[0]:
                                st.write(f"**#{i + 1}**")
                            with cols[1]:
                                st.write(f"**SMILES:** `{smile}`")
                            with cols[2]:
                                if isinstance(pred, float):
                                    st.write(f"**é¢„æµ‹çš„åŒ–å­¦ä½ç§»:** {pred:.4f} ppm")
                                else:
                                    st.write(f"**é”™è¯¯:** {pred}")
                    st.divider()
        else:
            st.warning("è¯·è‡³å°‘è¾“å…¥ä¸€ä¸ªSMILESå­—ç¬¦ä¸²ã€‚")

elif page == "å…³äº":
    # About page content
    st.title("å…³äºæœ¬åº”ç”¨")
    st.write("""
    æœ¬Webåº”ç”¨ç¨‹åºä½¿ç”¨å›¾ç¥ç»ç½‘ç»œ(GNN)æ¨¡å‹ä»åˆ†å­çš„SMILESè¡¨ç¤ºé¢„æµ‹åŒ–å­¦ä½ç§»ã€‚

    ### å·¥ä½œåŸç†
    1. **SMILESè¾“å…¥**: ç”¨æˆ·å¯ä»¥åœ¨æ–‡æœ¬åŒºåŸŸä¸­è¾“å…¥ä¸€ä¸ªæˆ–å¤šä¸ªSMILESå­—ç¬¦ä¸²(æ¯è¡Œä¸€ä¸ª)ã€‚
    2. **é€‰æ‹©æ¨¡å‹**: ç”¨æˆ·å¯ä»¥é€‰æ‹©ä½¿ç”¨AttentiveFPæˆ–GCNæ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚
    3. **é¢„æµ‹è¿‡ç¨‹**: åº”ç”¨ç¨‹åºå°†è¿™äº›SMILESå­—ç¬¦ä¸²è½¬æ¢ä¸ºå›¾è¡¨ç¤ºï¼Œå¹¶å°†å®ƒä»¬è¾“å…¥é¢„è®­ç»ƒçš„æ¨¡å‹ã€‚
    4. **è¾“å‡ºç»“æœ**: æ¨¡å‹ä¸ºç»™å®šçš„SMILESå­—ç¬¦ä¸²é¢„æµ‹åŒ–å­¦ä½ç§»å€¼ã€‚
    5. **æ•°æ®å½’ä¸€åŒ–**: æ¨¡å‹è¾“å‡ºçš„é¢„æµ‹å€¼ä¼šé€šè¿‡é€†å½’ä¸€åŒ–è½¬æ¢ä¸ºå®é™…çš„åŒ–å­¦ä½ç§»å€¼(ppm)ã€‚ä½¿ç”¨çš„å½’ä¸€åŒ–å‚æ•°:
       - ä¸­å¿ƒå€¼(center): 23.47
       - ç¼©æ”¾å› å­(scale): 22.69999886

    ### å…³äºåŒ–å­¦ä½ç§»
    åŒ–å­¦ä½ç§»æ˜¯æ ¸ç£å…±æŒ¯(NMR)è°±å­¦ä¸­çš„ä¸€ä¸ªé‡è¦å‚æ•°ï¼Œå®ƒè¡¨ç¤ºåˆ†å­ä¸­ç‰¹å®šåŸå­æ ¸çš„å…±æŒ¯é¢‘ç‡ä¸å‚è€ƒç‰©è´¨çš„åå·®ã€‚åŒ–å­¦ä½ç§»å—åˆ†å­ç»“æ„å½±å“ï¼Œå¯ç”¨äºåˆ†å­ç»“æ„é‰´å®šå’Œåˆ†æã€‚

    ### å…³äºæ¨¡å‹
    æœ¬åº”ç”¨æä¾›ä¸¤ç§ä¸åŒçš„å›¾ç¥ç»ç½‘ç»œæ¨¡å‹:

    #### AttentiveFPæ¨¡å‹å‚æ•°:
    - èŠ‚ç‚¹ç‰¹å¾ç»´åº¦: 9
    - éšè—å±‚ç»´åº¦: 66
    - è¾“å‡ºç»´åº¦: 1
    - è¾¹ç‰¹å¾ç»´åº¦: 3
    - å±‚æ•°: 5
    - æ—¶é—´æ­¥æ•°: 3
    - Dropoutç‡: 0.0446259777448801

    #### GCNæ¨¡å‹å‚æ•°:
    - èŠ‚ç‚¹ç‰¹å¾ç»´åº¦: 9
    - éšè—å±‚ç»´åº¦: 185
    - è¾“å‡ºç»´åº¦: 1
    - å±‚æ•°: 4
    - Dropoutç‡: 0.11080081715730111
    - æ± åŒ–æ–¹æ³•: max
    - æ¿€æ´»å‡½æ•°: relu
    """)

    st.write("### æŠ€æœ¯æ ˆ")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.info("**PyTorch & PyTorch Geometric**\n\nç”¨äºå›¾ç¥ç»ç½‘ç»œçš„è®­ç»ƒå’Œæ¨ç†")
    with col2:
        st.info("**Streamlit**\n\nç”¨äºæ„å»ºäº¤äº’å¼Webç•Œé¢")
    with col3:
        st.info("**RDKit**\n\nç”¨äºåˆ†å­å¤„ç†å’ŒSMILESè½¬æ¢")

